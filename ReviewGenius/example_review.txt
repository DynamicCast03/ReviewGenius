# AI基础复习资料

## 1. 绪论

*   **人工智能 (AI) 的定义:** 使机器能够像人类一样思考、学习和解决问题的科学与工程。
*   **AI 的目标:**  理解智能的本质，并创造出具有智能行为的机器。
*   **AI 的主要领域:**
    *   机器学习 (ML)
    *   深度学习 (DL)
    *   自然语言处理 (NLP)
    *   计算机视觉 (CV)
    *   机器人学
    *   知识表示与推理
*   **AI 的发展历史:**  简述AI发展的重要阶段和里程碑事件。
*   **AI 的应用:**  列举AI在各行各业的应用实例。

## 2. 机器学习 (ML)

### 2.1 机器学习概述

*   **定义:**  使计算机系统能够从数据中学习，而无需显式编程。
*   **主要类型:**
    *   **监督学习 (Supervised Learning):**  使用带有标签的数据进行训练。
        *   **分类 (Classification):**  预测离散的类别标签。
        *   **回归 (Regression):**  预测连续的数值。
    *   **无监督学习 (Unsupervised Learning):**  使用没有标签的数据进行训练。
        *   **聚类 (Clustering):**  将数据分成不同的组。
        *   **降维 (Dimensionality Reduction):**  减少数据的维度，同时保留重要信息。
    *   **强化学习 (Reinforcement Learning):**  通过与环境交互来学习最佳策略。
*   **机器学习的步骤:**
    1.  数据收集
    2.  数据预处理
    3.  特征工程
    4.  模型选择
    5.  模型训练
    6.  模型评估
    7.  模型部署

### 2.2 监督学习

*   **常用算法:**
    *   **线性回归 (Linear Regression):**  用于回归问题，假设特征和目标变量之间存在线性关系。
        *   公式： $$y = wx + b$$
    *   **逻辑回归 (Logistic Regression):**  用于分类问题，预测样本属于某个类别的概率。
        *   公式： $$P(y=1|x) = \frac{1}{1 + e^{-(wx + b)}}$$
    *   **支持向量机 (SVM):**  寻找一个最优超平面来分隔不同类别的数据。
    *   **决策树 (Decision Tree):**  基于树结构进行决策，易于理解和解释。
    *   **随机森林 (Random Forest):**  多个决策树的集成，提高模型的泛化能力。
    *   **K近邻 (KNN):**  根据距离最近的K个样本的类别来预测新样本的类别。
*   **评估指标:**
    *   **分类:** 准确率 (Accuracy), 精确率 (Precision), 召回率 (Recall), F1 值 (F1-score), AUC-ROC 曲线
    *   **回归:** 均方误差 (MSE), 均方根误差 (RMSE), 平均绝对误差 (MAE), R 平方 (R-squared)

### 2.3 无监督学习

*   **常用算法:**
    *   **K均值聚类 (K-Means Clustering):**  将数据分成K个簇，每个簇有一个中心点。
    *   **层次聚类 (Hierarchical Clustering):**  通过构建层次结构来聚类数据。
    *   **主成分分析 (PCA):**  将数据投影到新的坐标系中，使得方差最大化的方向成为主成分。
    *   **t-分布邻域嵌入 (t-SNE):**  用于高维数据的可视化，将高维数据降维到二维或三维空间，同时保留数据的局部结构。
*   **评估指标:**
    *   轮廓系数 (Silhouette Coefficient)
    *   Calinski-Harabasz 指数

### 2.4 模型评估与选择

*   **过拟合 (Overfitting):**  模型在训练数据上表现很好，但在测试数据上表现很差。
*   **欠拟合 (Underfitting):**  模型在训练数据和测试数据上都表现不好。
*   **交叉验证 (Cross-Validation):**  将数据分成多个子集，轮流作为验证集，评估模型的泛化能力。
*   **正则化 (Regularization):**  通过添加惩罚项来防止过拟合。
    *   L1 正则化 (Lasso)
    *   L2 正则化 (Ridge)
*   **模型选择:**  根据问题的类型和数据的特点选择合适的模型。

## 3. 深度学习 (DL)

### 3.1 深度学习概述

*   **定义:**  一种基于人工神经网络的机器学习方法。
*   **神经网络 (Neural Network):**  由多个神经元连接而成，每个神经元接收输入，进行加权求和，并通过激活函数输出。
*   **主要类型:**
    *   **多层感知机 (MLP):**  最基本的深度学习模型，由多个全连接层组成。
    *   **卷积神经网络 (CNN):**  主要用于图像处理，通过卷积操作提取图像特征。
    *   **循环神经网络 (RNN):**  主要用于序列数据处理，具有记忆能力。
    *   **长短期记忆网络 (LSTM):**  一种特殊的RNN，可以解决梯度消失问题。
    *   **Transformer:**  基于自注意力机制，在自然语言处理领域取得了巨大成功。
*   **深度学习的优势:**  可以自动学习特征，处理复杂的数据。

### 3.2 常用算法

*   **卷积神经网络 (CNN)**
    *   **卷积层 (Convolutional Layer):**  使用卷积核对输入图像进行卷积操作，提取图像特征。
    *   **池化层 (Pooling Layer):**  减小特征图的尺寸，降低计算量，并提高模型的鲁棒性。
    *   **激活函数 (Activation Function):**  引入非线性，增强模型的表达能力。常用的激活函数有 ReLU, Sigmoid, Tanh 等。
    *   **经典 CNN 网络:** LeNet, AlexNet, VGG, ResNet, Inception 等
*   **循环神经网络 (RNN)**
    *   **循环单元 (Recurrent Unit):**  将当前时刻的输入和上一时刻的隐藏状态作为输入，输出当前时刻的隐藏状态。
    *   **梯度消失 (Vanishing Gradient):**  RNN 训练过程中容易出现梯度消失问题。
    *   **LSTM 和 GRU:**  可以有效解决梯度消失问题。
*   **Transformer**
    *   **自注意力机制 (Self-Attention):**  计算输入序列中每个位置与其他位置之间的关系，从而更好地理解序列的含义。
    *   **编码器 (Encoder) 和解码器 (Decoder):**  Transformer 由编码器和解码器组成，编码器将输入序列转换为隐藏表示，解码器根据隐藏表示生成输出序列。
    *   **Transformer 的优势:**  可以并行计算，处理长序列数据。

### 3.3 训练技巧

*   **梯度下降 (Gradient Descent):**  通过迭代更新模型参数，使损失函数最小化。
    *   **批量梯度下降 (Batch Gradient Descent):**  每次迭代使用所有样本计算梯度。
    *   **随机梯度下降 (Stochastic Gradient Descent):**  每次迭代使用一个样本计算梯度。
    *   **小批量梯度下降 (Mini-Batch Gradient Descent):**  每次迭代使用一小部分样本计算梯度。
*   **学习率 (Learning Rate):**  控制参数更新的步长。
*   **优化器 (Optimizer):**  用于更新模型参数的算法。常用的优化器有 Adam, SGD, RMSprop 等。
*   **批量归一化 (Batch Normalization):**  加速模型训练，提高模型的泛化能力。
*   **Dropout:**  随机丢弃一部分神经元，防止过拟合。
*   **权重初始化 (Weight Initialization):**  合适的权重初始化可以加速模型训练。

## 4. 自然语言处理 (NLP)

*   **定义:**  使计算机能够理解和处理人类语言的科学与工程。
*   **主要任务:**
    *   **文本分类 (Text Classification):**  将文本分成不同的类别。
    *   **命名实体识别 (NER):**  识别文本中的命名实体，如人名、地名、组织机构名等。
    *   **机器翻译 (Machine Translation):**  将一种语言的文本翻译成另一种语言。
    *   **文本摘要 (Text Summarization):**  生成文本的摘要。
    *   **问答系统 (Question Answering):**  根据问题从文本中找到答案。
*   **常用技术:**
    *   **词嵌入 (Word Embedding):**  将词语表示成向量，常用的词嵌入模型有 Word2Vec, GloVe, FastText 等。
    *   **循环神经网络 (RNN) 和 LSTM:**  用于处理序列数据，如文本。
    *   **Transformer:**  在自然语言处理领域取得了巨大成功。
*   **常用数据集:**
    *   IMDB 电影评论数据集
    *   路透社新闻数据集
    *   SQuAD 问答数据集

## 5. 计算机视觉 (CV)

*   **定义:**  使计算机能够“看”和理解图像的科学与工程。
*   **主要任务:**
    *   **图像分类 (Image Classification):**  将图像分成不同的类别。
    *   **目标检测 (Object Detection):**  在图像中检测出目标物体，并给出其位置和类别。
    *   **图像分割 (Image Segmentation):**  将图像分割成不同的区域，每个区域代表一个物体或背景。
    *   **图像生成 (Image Generation):**  生成新的图像。
*   **常用技术:**
    *   **卷积神经网络 (CNN):**  用于提取图像特征。
    *   **目标检测算法:** R-CNN 系列 (R-CNN, Fast R-CNN, Faster R-CNN), YOLO 系列 (YOLOv3, YOLOv4, YOLOv5), SSD 等。
    *   **图像分割算法:** FCN, U-Net, Mask R-CNN 等。
*   **常用数据集:**
    *   ImageNet
    *   COCO
    *   MNIST

## 6. 知识表示与推理

*   **知识表示:**  将知识以计算机可以理解和处理的形式表示出来。常用的知识表示方法有：
    *   **谓词逻辑 (Predicate Logic)**
    *   **语义网络 (Semantic Network)**
    *   **框架 (Frame)**
    *   **本体 (Ontology)**
*   **推理:**  根据已知的知识推导出新的知识。常用的推理方法有：
    *   **演绎推理 (Deductive Reasoning)**
    *   **归纳推理 (Inductive Reasoning)**
    *   **溯因推理 (Abductive Reasoning)**

